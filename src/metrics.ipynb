{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.506909Z",
     "start_time": "2021-05-22T23:40:42.225667Z"
    }
   },
   "outputs": [],
   "source": [
    "from rouge import rouge_n_sentence_level\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import nltk\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.512156Z",
     "start_time": "2021-05-22T23:40:43.509036Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(138290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.518382Z",
     "start_time": "2021-05-22T23:40:43.514424Z"
    }
   },
   "outputs": [],
   "source": [
    "def avg_n_rouge(list1, list2, n=2):\n",
    "    \n",
    "    rouge_sum = 0\n",
    "    \n",
    "    for i in range(len(list1)):\n",
    "        \n",
    "        _, _, rouge = rouge_n_sentence_level(list1[i],list2[i], n)\n",
    "        \n",
    "        rouge_sum += rouge\n",
    "    \n",
    "    rouge_avg = rouge_sum / len(list1)\n",
    "    \n",
    "    return rouge_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.525699Z",
     "start_time": "2021-05-22T23:40:43.520845Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_avg_bleu(list1,list2):\n",
    "    '''\n",
    "    -----------------------\n",
    "    Get smoothed average \n",
    "    BLEU score\n",
    "    -----------------------\n",
    "    '''\n",
    "    sum_bleu = 0\n",
    "    \n",
    "    smoothie = SmoothingFunction().method5\n",
    "    \n",
    "    for i in range(len(list1)):\n",
    "        \n",
    "        hypothesis = list1[i].split(' ')\n",
    "        \n",
    "        reference = list2[i].split(' ')\n",
    "        \n",
    "        # The maximum is bigram so assign the weight into 2 half\n",
    "        score = nltk.translate.bleu_score.sentence_bleu([reference], \n",
    "                                                        hypothesis, \n",
    "                                                        weights = (0.5, 0.5), \n",
    "                                                        smoothing_function = smoothie)\n",
    "        sum_bleu += score\n",
    "    \n",
    "    avg_bleu = sum_bleu/len(list1)\n",
    "    \n",
    "    return avg_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.531521Z",
     "start_time": "2021-05-22T23:40:43.527587Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_number_of_ingredient_used(ingredient_list, text):\n",
    "    '''\n",
    "    ------------\n",
    "    Get fraction of ingredients used by\n",
    "    ------------\n",
    "    '''\n",
    "    ing_count = 0\n",
    "    \n",
    "    for ing in ingredient_list :\n",
    "        \n",
    "        if ing in text :\n",
    "            \n",
    "            ing_count += 1\n",
    "    \n",
    "    ing_frac = ing_count/len(ingredient_list)\n",
    "    \n",
    "    return ing_frac\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.537506Z",
     "start_time": "2021-05-22T23:40:43.533380Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_number_of_ingredient_used_2(ingredient_list, text):\n",
    "    '''\n",
    "    ------------\n",
    "    Get number of ingredients used \n",
    "    ------------\n",
    "    '''\n",
    "    ing_count = 0\n",
    "    \n",
    "    total_words = 0\n",
    "    \n",
    "    for ing in ingredient_list :\n",
    "        \n",
    "        ings = ing.split(' ')\n",
    "        \n",
    "        total_words += len(ings) \n",
    "        \n",
    "        for i in ings :\n",
    "            \n",
    "            if i in text :\n",
    "                \n",
    "                ing_count += 1\n",
    "                \n",
    "    ing_frac = ing_count/total_words\n",
    "    \n",
    "    return ing_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.544455Z",
     "start_time": "2021-05-22T23:40:43.540033Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_ing_vocab(x):\n",
    "    '''\n",
    "    ----------\n",
    "    Return ingredient vocabulary\n",
    "    ----------\n",
    "    '''\n",
    "    return set(ing for ing_list in x[1] for ing in ing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.553079Z",
     "start_time": "2021-05-22T23:40:43.548796Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_extra_ingredient_used(ingredient_list, ing_vocab, text):\n",
    "    '''\n",
    "    ------------\n",
    "    Get fraction of ingredients used by\n",
    "    ------------\n",
    "    '''\n",
    "    extra_ing_count = 0\n",
    "    \n",
    "    for word in text:\n",
    "    \n",
    "        if word not in ingredient_list:\n",
    "        \n",
    "            if word in ing_vocab:\n",
    "            \n",
    "                extra_ing_count += 1\n",
    "    \n",
    "    extra_ing_frac = extra_ing_count/len(ingredient_list)\n",
    "    \n",
    "    return extra_ing_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.561772Z",
     "start_time": "2021-05-22T23:40:43.555791Z"
    }
   },
   "outputs": [],
   "source": [
    "def ingredients_overlap(txt, label, vocab):\n",
    "    \n",
    "    label_lst = []\n",
    "    txt_lst = []\n",
    "    \n",
    "    for word in vocab:\n",
    "        if word in txt:\n",
    "            txt_lst.append(word)\n",
    "        if word in label:\n",
    "            label_lst.append(word)\n",
    "            \n",
    "    label_lst = set(label_lst)\n",
    "    txt_lst = set(txt_lst)\n",
    "        \n",
    "    intersection = label_lst.intersection(txt_lst)\n",
    "    \n",
    "    return len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.577527Z",
     "start_time": "2021-05-22T23:40:43.564299Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_results(f, results_path = \"results/\", checklist=False):\n",
    "    '''\n",
    "    Execute all code\n",
    "    '''\n",
    "    \n",
    "    if checklist:\n",
    "        # Load File\n",
    "        x = json.load(open(os.path.join(results_path, f), \"r\" ))\n",
    "        # Process \n",
    "        x = process_checklist_output(x)\n",
    "    else:\n",
    "        # Load files\n",
    "        x = pkl.load(open(os.path.join(results_path, f), \"rb\" ))\n",
    "    \n",
    "    # Masking column description\n",
    "    if '0.8' in f: \n",
    "        masking = 0.8\n",
    "    if '0.5' in f:\n",
    "        masking = 0.5\n",
    "    \n",
    "    # Model type description\n",
    "    if 'frozen_encoder' in f:\n",
    "        model_type = 'Encoder frozen'\n",
    "    \n",
    "    elif 'all_layers' in f: \n",
    "        model_type = 'All layers'\n",
    "    else:\n",
    "        model_type = 'Checklist'\n",
    "\n",
    "    # Rouge 2 score\n",
    "    rouge_2_avg = avg_n_rouge(x[2],x[3])\n",
    "    \n",
    "    # Rouge 4 Score\n",
    "    rouge_4_avg = avg_n_rouge(x[2], x[3], n=4)\n",
    "    \n",
    "    # BLEU score\n",
    "    bleu_avg = get_avg_bleu(x[3],x[2])\n",
    "    \n",
    "    # Coherence of output\n",
    "    ing_frac = [get_number_of_ingredient_used(x[1][i],x[2][i]) for i in range(len(x[1]))]\n",
    "    \n",
    "    overall_frac_1 = sum(ing_frac)/len(ing_frac)  \n",
    "    \n",
    "    # Coherence of target\n",
    "    ing_frac_2 = [get_number_of_ingredient_used_2(x[1][i],x[3][i]) for i in range(len(x[1]))]\n",
    "    \n",
    "    overall_frac_2 = sum(ing_frac_2)/len(ing_frac_2)\n",
    "    \n",
    "    # Compute overall coherence\n",
    "    overall_coherence = overall_frac_1/overall_frac_2\n",
    "    \n",
    "    # Ingredients Intersection\n",
    "    ing_vocab = make_ing_vocab(x)\n",
    "    \n",
    "    overlap = [ingredients_overlap(x[2][i], x[3][i], ing_vocab) for i in range(len(x[1]))]\n",
    "    \n",
    "    avg_overlap = sum(overlap)/len(overlap)\n",
    "    \n",
    "    # Put results together\n",
    "    results = [model_type, masking, rouge_2_avg, rouge_4_avg, bleu_avg, \n",
    "               overall_frac_1, overall_frac_2, overall_coherence, overall_frac_1, avg_overlap]\n",
    "    \n",
    "    ing_fracs = [ing_frac, ing_frac_2]\n",
    "    \n",
    "    # Return statement\n",
    "    return(results, ing_fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.585674Z",
     "start_time": "2021-05-22T23:40:43.580379Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_examples_qualitative(x):\n",
    "    '''\n",
    "    Generate indices for qualitative examples\n",
    "    '''\n",
    "    n = len(x)\n",
    "    \n",
    "    indices = np.random.choice(np.arange(n), size=100)\n",
    "    \n",
    "    return(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.605206Z",
     "start_time": "2021-05-22T23:40:43.599644Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_checklist_output(x):\n",
    "    \n",
    "    y = []\n",
    "    y.append(x['goal'])\n",
    "    y.append(x['ingredients'])\n",
    "    y.append([' '.join(lst) for lst in x['generated_text']])\n",
    "    y.append([' '.join(lst) for lst in x['label']])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:45:34.982194Z",
     "start_time": "2021-05-22T23:40:43.608769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.5_checklist.json', '0.8_checklist.json']\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    get_indices = 0\n",
    "    \n",
    "    results_path = \"./../results/\"\n",
    "    \n",
    "    files = [f for f in os.listdir(results_path) if f.endswith(\".pkl\")]\n",
    "    chk_files = [f for f in os.listdir(results_path) if f.endswith(\".json\")]\n",
    "    \n",
    "    print(chk_files)\n",
    "    \n",
    "    columns = [\"Model type\", \"Masking level\", \"Rouge 2 Score\", \"Rouge 4 Score\", \"BLEU Score\", \n",
    "               \"Coherence: output\", \"Coherence: target\", \"Coherence: Overall\", \"Avg Ingredients\",\n",
    "              \"Avg Overlap\"]\n",
    "\n",
    "    results = [get_results(f, results_path) for f in files]\n",
    "    chk_results = [get_results(f, results_path, checklist=True) for f in chk_files]\n",
    "    \n",
    "    res = pd.DataFrame([r[0] for r in results], columns = columns)\n",
    "    chk_res = pd.DataFrame([r[0] for r in chk_results], columns = columns)\n",
    "    \n",
    "\n",
    "    if get_indices == 1:\n",
    "    \n",
    "        x = pkl.load(open(os.path.join(results_path, files[0]), \"rb\" ))    \n",
    "        \n",
    "        ing = [r[1] for r in results]\n",
    "    \n",
    "        indices = gen_examples_qualitative(x[0])\n",
    "    \n",
    "        pd.DataFrame(indices).to_csv(os.path.join(results_path, \"indices.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model type</th>\n",
       "      <th>Masking level</th>\n",
       "      <th>Rouge 2 Score</th>\n",
       "      <th>Rouge 4 Score</th>\n",
       "      <th>BLEU Score</th>\n",
       "      <th>Coherence: output</th>\n",
       "      <th>Coherence: target</th>\n",
       "      <th>Coherence: Overall</th>\n",
       "      <th>Avg Ingredients</th>\n",
       "      <th>Avg Overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Checklist</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.422208</td>\n",
       "      <td>0.209473</td>\n",
       "      <td>0.136464</td>\n",
       "      <td>0.237049</td>\n",
       "      <td>0.256449</td>\n",
       "      <td>0.924352</td>\n",
       "      <td>0.237049</td>\n",
       "      <td>2.405466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Checklist</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.499655</td>\n",
       "      <td>0.253661</td>\n",
       "      <td>0.190788</td>\n",
       "      <td>0.332317</td>\n",
       "      <td>0.445138</td>\n",
       "      <td>0.746549</td>\n",
       "      <td>0.332317</td>\n",
       "      <td>4.491596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model type  Masking level  Rouge 2 Score  Rouge 4 Score  BLEU Score  \\\n",
       "0  Checklist            0.5       0.422208       0.209473    0.136464   \n",
       "1  Checklist            0.8       0.499655       0.253661    0.190788   \n",
       "\n",
       "   Coherence: output  Coherence: target  Coherence: Overall  Avg Ingredients  \\\n",
       "0           0.237049           0.256449            0.924352         0.237049   \n",
       "1           0.332317           0.445138            0.746549         0.332317   \n",
       "\n",
       "   Avg Overlap  \n",
       "0     2.405466  \n",
       "1     4.491596  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model type</th>\n",
       "      <th>Masking level</th>\n",
       "      <th>Rouge 2 Score</th>\n",
       "      <th>Rouge 4 Score</th>\n",
       "      <th>BLEU Score</th>\n",
       "      <th>Coherence: output</th>\n",
       "      <th>Coherence: target</th>\n",
       "      <th>Coherence: Overall</th>\n",
       "      <th>Avg Ingredients</th>\n",
       "      <th>Avg Overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Encoder frozen</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.550120</td>\n",
       "      <td>0.281836</td>\n",
       "      <td>0.351300</td>\n",
       "      <td>0.183054</td>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.183054</td>\n",
       "      <td>2.700667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Encoder frozen</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.603436</td>\n",
       "      <td>0.315782</td>\n",
       "      <td>0.367697</td>\n",
       "      <td>0.375699</td>\n",
       "      <td>0.437575</td>\n",
       "      <td>0.858593</td>\n",
       "      <td>0.375699</td>\n",
       "      <td>5.758032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All layers</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.581412</td>\n",
       "      <td>0.326618</td>\n",
       "      <td>0.387385</td>\n",
       "      <td>0.187615</td>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.738355</td>\n",
       "      <td>0.187615</td>\n",
       "      <td>3.171048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All layers</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.631610</td>\n",
       "      <td>0.357178</td>\n",
       "      <td>0.405573</td>\n",
       "      <td>0.371449</td>\n",
       "      <td>0.437575</td>\n",
       "      <td>0.848880</td>\n",
       "      <td>0.371449</td>\n",
       "      <td>6.206591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model type  Masking level  Rouge 2 Score  Rouge 4 Score  BLEU Score  \\\n",
       "0  Encoder frozen            0.5       0.550120       0.281836    0.351300   \n",
       "1  Encoder frozen            0.8       0.603436       0.315782    0.367697   \n",
       "2      All layers            0.5       0.581412       0.326618    0.387385   \n",
       "3      All layers            0.8       0.631610       0.357178    0.405573   \n",
       "\n",
       "   Coherence: output  Coherence: target  Coherence: Overall  Avg Ingredients  \\\n",
       "0           0.183054           0.254098            0.720405         0.183054   \n",
       "1           0.375699           0.437575            0.858593         0.375699   \n",
       "2           0.187615           0.254098            0.738355         0.187615   \n",
       "3           0.371449           0.437575            0.848880         0.371449   \n",
       "\n",
       "   Avg Overlap  \n",
       "0     2.700667  \n",
       "1     5.758032  \n",
       "2     3.171048  \n",
       "3     6.206591  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
