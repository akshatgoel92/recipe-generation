{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.506909Z",
     "start_time": "2021-05-22T23:40:42.225667Z"
    }
   },
   "outputs": [],
   "source": [
    "from rouge import rouge_n_sentence_level\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import nltk\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.512156Z",
     "start_time": "2021-05-22T23:40:43.509036Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(138290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.518382Z",
     "start_time": "2021-05-22T23:40:43.514424Z"
    }
   },
   "outputs": [],
   "source": [
    "def avg_n_rouge(list1, list2, n=2):\n",
    "    \n",
    "    rouge_sum = 0\n",
    "    \n",
    "    for i in range(len(list1)):\n",
    "        \n",
    "        _, _, rouge = rouge_n_sentence_level(list1[i],list2[i], n)\n",
    "        \n",
    "        rouge_sum += rouge\n",
    "    \n",
    "    rouge_avg = rouge_sum / len(list1)\n",
    "    \n",
    "    return rouge_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.525699Z",
     "start_time": "2021-05-22T23:40:43.520845Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_avg_bleu(list1,list2):\n",
    "    '''\n",
    "    -----------------------\n",
    "    Get smoothed average \n",
    "    BLEU score\n",
    "    -----------------------\n",
    "    '''\n",
    "    sum_bleu = 0\n",
    "    \n",
    "    smoothie = SmoothingFunction().method5\n",
    "    \n",
    "    for i in range(len(list1)):\n",
    "        \n",
    "        hypothesis = list1[i].split(' ')\n",
    "        \n",
    "        reference = list2[i].split(' ')\n",
    "        \n",
    "        # The maximum is bigram so assign the weight into 2 half\n",
    "        score = nltk.translate.bleu_score.sentence_bleu([reference], \n",
    "                                                        hypothesis, \n",
    "                                                        weights = (0.5, 0.5), \n",
    "                                                        smoothing_function = smoothie)\n",
    "        sum_bleu += score\n",
    "    \n",
    "    avg_bleu = sum_bleu/len(list1)\n",
    "    \n",
    "    return avg_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.531521Z",
     "start_time": "2021-05-22T23:40:43.527587Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_number_of_ingredient_used(ingredient_list, text):\n",
    "    '''\n",
    "    ------------\n",
    "    Get fraction of ingredients used by\n",
    "    ------------\n",
    "    '''\n",
    "    ing_count = 0\n",
    "    \n",
    "    for ing in ingredient_list :\n",
    "        \n",
    "        if ing in text :\n",
    "            \n",
    "            ing_count += 1\n",
    "    \n",
    "    ing_frac = ing_count/len(ingredient_list)\n",
    "    \n",
    "    return ing_frac\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.537506Z",
     "start_time": "2021-05-22T23:40:43.533380Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_number_of_ingredient_used_2(ingredient_list, text):\n",
    "    '''\n",
    "    ------------\n",
    "    Get number of ingredients used \n",
    "    ------------\n",
    "    '''\n",
    "    ing_count = 0\n",
    "    \n",
    "    total_words = 0\n",
    "    \n",
    "    for ing in ingredient_list :\n",
    "        \n",
    "        ings = ing.split(' ')\n",
    "        \n",
    "        total_words += len(ings) \n",
    "        \n",
    "        for i in ings :\n",
    "            \n",
    "            if i in text :\n",
    "                \n",
    "                ing_count += 1\n",
    "                \n",
    "    ing_frac = ing_count/total_words\n",
    "    \n",
    "    return ing_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.544455Z",
     "start_time": "2021-05-22T23:40:43.540033Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_ing_vocab(x):\n",
    "    '''\n",
    "    ----------\n",
    "    Return ingredient vocabulary\n",
    "    ----------\n",
    "    '''\n",
    "    return set(ing for ing_list in x[1] for ing in ing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.553079Z",
     "start_time": "2021-05-22T23:40:43.548796Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_extra_ingredient_used(ingredient_list, ing_vocab, text):\n",
    "    '''\n",
    "    ------------\n",
    "    Get fraction of ingredients used by\n",
    "    ------------\n",
    "    '''\n",
    "    extra_ing_count = 0\n",
    "    \n",
    "    for word in text:\n",
    "    \n",
    "        if word not in ingredient_list:\n",
    "        \n",
    "            if word in ing_vocab:\n",
    "            \n",
    "                extra_ing_count += 1\n",
    "    \n",
    "    extra_ing_frac = extra_ing_count/len(ingredient_list)\n",
    "    \n",
    "    return extra_ing_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.561772Z",
     "start_time": "2021-05-22T23:40:43.555791Z"
    }
   },
   "outputs": [],
   "source": [
    "def ingredients_overlap(txt, label, vocab):\n",
    "    \n",
    "    label_lst = []\n",
    "    txt_lst = []\n",
    "    \n",
    "    for word in vocab:\n",
    "        if word in txt:\n",
    "            txt_lst.append(word)\n",
    "        if word in label:\n",
    "            label_lst.append(word)\n",
    "            \n",
    "    label_lst = set(label_lst)\n",
    "    txt_lst = set(txt_lst)\n",
    "        \n",
    "    intersection = label_lst.intersection(txt_lst)\n",
    "    \n",
    "    return len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.577527Z",
     "start_time": "2021-05-22T23:40:43.564299Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_results(f, results_path = \"results/\", checklist=False):\n",
    "    '''\n",
    "    Execute all code\n",
    "    '''\n",
    "    \n",
    "    if checklist:\n",
    "        # Load File\n",
    "        x = json.load(open(os.path.join(results_path, f), \"r\" ))\n",
    "        # Process \n",
    "        x = process_checklist_output(x)\n",
    "    else:\n",
    "        # Load files\n",
    "        x = pkl.load(open(os.path.join(results_path, f), \"rb\" ))\n",
    "    \n",
    "    # Masking column description\n",
    "    if '0.8' in f: \n",
    "        masking = 0.8\n",
    "    if '0.5' in f:\n",
    "        masking = 0.5\n",
    "    \n",
    "    # Model type description\n",
    "    if 'frozen_encoder' in f:\n",
    "        model_type = 'Encoder frozen'\n",
    "    elif 'all_layers' in f: \n",
    "        model_type = 'All layers'\n",
    "    else:\n",
    "        model_type = 'Checklist'\n",
    "\n",
    "    # Rouge 2 score\n",
    "    rouge_2_avg = avg_n_rouge(x[2],x[3])\n",
    "    \n",
    "    # Rouge 4 Score\n",
    "    rouge_4_avg = avg_n_rouge(x[2], x[3], n=4)\n",
    "    \n",
    "    # BLEU score\n",
    "    bleu_avg = get_avg_bleu(x[3],x[2])\n",
    "    \n",
    "    # Coherence of output\n",
    "    ing_frac = [get_number_of_ingredient_used(x[1][i],x[2][i]) for i in range(len(x[1]))]\n",
    "    \n",
    "    overall_frac_1 = sum(ing_frac)/len(ing_frac)  \n",
    "    \n",
    "    # Coherence of target\n",
    "    ing_frac_2 = [get_number_of_ingredient_used_2(x[1][i],x[3][i]) for i in range(len(x[1]))]\n",
    "    \n",
    "    overall_frac_2 = sum(ing_frac_2)/len(ing_frac_2)\n",
    "    \n",
    "    # Compute overall coherence\n",
    "    overall_coherence = overall_frac_1/overall_frac_2\n",
    "    \n",
    "    # Ingredients Intersection\n",
    "    \n",
    "    ing_vocab = make_ing_vocab(x)\n",
    "    overlap = [ingredients_overlap(x[2][i], x[3][i], ing_vocab) for i in range(len(x[1]))]\n",
    "    avg_overlap = sum(overlap)/len(overlap)\n",
    "    \n",
    "    # Put results together\n",
    "    results = [model_type, masking, rouge_2_avg, rouge_4_avg, bleu_avg, \n",
    "               overall_frac_1, overall_frac_2, overall_coherence, overall_frac_1, avg_overlap]\n",
    "    \n",
    "    ing_fracs = [ing_frac, ing_frac_2]\n",
    "    \n",
    "    # Return statement\n",
    "    return(results, ing_fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.585674Z",
     "start_time": "2021-05-22T23:40:43.580379Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_examples_qualitative(x):\n",
    "    '''\n",
    "    Generate indices for qualitative examples\n",
    "    '''\n",
    "    n = len(x)\n",
    "    \n",
    "    indices = np.random.choice(np.arange(n), size=100)\n",
    "    \n",
    "    return(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.596661Z",
     "start_time": "2021-05-22T23:40:43.588924Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weird_examples(f, results_path = \"/Users/akshatgoel/Desktop/results/\"):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # Print the file name\n",
    "    print(f)\n",
    "    \n",
    "    # Load the file\n",
    "    x = pkl.load(open(os.path.join(results_path, f), \"rb\" ))\n",
    "    \n",
    "    test = np.array(ing[0][1])\n",
    "    \n",
    "    test_indices = np.squeeze(np.where(test == 0)[0])\n",
    "    \n",
    "    for i in test_indices[:n]:\n",
    "        \n",
    "        print(x[0][i])\n",
    "        \n",
    "        print(x[1][i])\n",
    "        \n",
    "        print(x[2][i])\n",
    "        \n",
    "        print(x[3][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:40:43.605206Z",
     "start_time": "2021-05-22T23:40:43.599644Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_checklist_output(x):\n",
    "    \n",
    "    y = []\n",
    "    y.append(x['goal'])\n",
    "    y.append(x['ingredients'])\n",
    "    y.append([' '.join(lst) for lst in x['generated_text']])\n",
    "    y.append([' '.join(lst) for lst in x['label']])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T23:45:34.982194Z",
     "start_time": "2021-05-22T23:40:43.608769Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    results_path = \"results/\"\n",
    "    \n",
    "    files = [f for f in os.listdir(results_path) if f.endswith(\".pkl\")]\n",
    "    chk_files = [f for f in os.listdir(results_path) if f.endswith(\".json\")]\n",
    "    \n",
    "    # x = pkl.load(open(os.path.join(results_path, files[0]), \"rb\" ))\n",
    "\n",
    "    \n",
    "    columns = [\"Model type\", \"Masking level\", \"Rouge 2 Score\", \"Rouge 4 Score\", \"BLEU Score\", \n",
    "               \"Coherence: output\", \"Coherence: target\", \"Coherence: Overall\", \"Avg Ingredients\",\n",
    "              \"Avg Overlap\"]\n",
    "\n",
    "    #results = [get_results(f) for f in files]\n",
    "    chk_results = [get_results(f, checklist=True) for f in chk_files]\n",
    "    \n",
    "    #res = pd.DataFrame([r[0] for r in results], columns = columns)\n",
    "    chk_res = pd.DataFrame([r[0] for r in chk_results], columns = columns)\n",
    "    \n",
    "#     ing = [r[1] for r in results]\n",
    "    \n",
    "#     indices = gen_examples_qualitative(x[0])\n",
    "    \n",
    "#     pd.DataFrame(indices).to_csv(os.path.join(results_path, \"indices.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
